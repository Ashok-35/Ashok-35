{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer using Neural network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgBWc9Gjma9p",
        "outputId": "3f6923da-8488-41c8-9e60-ab63522ab598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/digit-recognizer.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/digit-recognizer.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "u80z18kxtnok"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "_tcVi-ZKuH0e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDbauRcmuKJ7",
        "outputId": "b01aedcc-aa62-4bed-dd08-28fb74345ef2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 785)\n",
            "(28000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.iloc[:,1:]\n",
        "Y = train['label']"
      ],
      "metadata": {
        "id": "OYOMHI6-ukFP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=123)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWHN1ZpouQc2",
        "outputId": "41b0588b-2fea-4970-8214-f71070972c72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33600, 784)\n",
            "(8400, 784)\n",
            "(33600,)\n",
            "(8400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per = Perceptron(verbose=1)\n",
        "per.fit(x_train,y_train)\n",
        "preds_per = per.predict(x_test)\n",
        "cm_slp = confusion_matrix(y_test, preds_per)\n",
        "clas_rep_slp = classification_report(y_test,preds_per)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ai3PHwTub1T",
        "outputId": "2be52904-101c-4dcb-8079-b16a5383bd0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 33680.40, NNZs: 599, Bias: -92.000000, T: 33600, Avg. loss: 46817.951667\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 42819.49, NNZs: 607, Bias: -161.000000, T: 67200, Avg. loss: 41184.869077\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 48607.75, NNZs: 614, Bias: -222.000000, T: 100800, Avg. loss: 36891.702232\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 54442.08, NNZs: 625, Bias: -281.000000, T: 134400, Avg. loss: 35999.461042\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 58608.01, NNZs: 631, Bias: -333.000000, T: 168000, Avg. loss: 37009.589702\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 61946.25, NNZs: 635, Bias: -383.000000, T: 201600, Avg. loss: 34799.316220\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 65207.63, NNZs: 637, Bias: -432.000000, T: 235200, Avg. loss: 36238.479613\n",
            "Total training time: 0.58 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 68995.89, NNZs: 639, Bias: -476.000000, T: 268800, Avg. loss: 34062.205625\n",
            "Total training time: 0.64 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 72716.99, NNZs: 639, Bias: -521.000000, T: 302400, Avg. loss: 32438.202173\n",
            "Total training time: 0.71 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 75447.16, NNZs: 639, Bias: -563.000000, T: 336000, Avg. loss: 32292.536667\n",
            "Total training time: 0.79 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 77822.41, NNZs: 639, Bias: -609.000000, T: 369600, Avg. loss: 34301.058214\n",
            "Total training time: 0.91 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 81007.01, NNZs: 639, Bias: -661.000000, T: 403200, Avg. loss: 35224.191131\n",
            "Total training time: 0.97 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 82890.94, NNZs: 639, Bias: -705.000000, T: 436800, Avg. loss: 33747.325863\n",
            "Total training time: 1.04 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 84973.26, NNZs: 639, Bias: -748.000000, T: 470400, Avg. loss: 31301.132321\n",
            "Total training time: 1.12 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 87757.36, NNZs: 639, Bias: -792.000000, T: 504000, Avg. loss: 32312.222708\n",
            "Total training time: 1.21 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 89517.12, NNZs: 639, Bias: -834.000000, T: 537600, Avg. loss: 31293.953988\n",
            "Total training time: 1.28 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 92120.81, NNZs: 639, Bias: -879.000000, T: 571200, Avg. loss: 31823.835923\n",
            "Total training time: 1.37 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 93354.02, NNZs: 639, Bias: -923.000000, T: 604800, Avg. loss: 32199.063512\n",
            "Total training time: 1.43 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 95389.80, NNZs: 639, Bias: -962.000000, T: 638400, Avg. loss: 31501.624494\n",
            "Total training time: 1.49 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 97060.82, NNZs: 639, Bias: -1013.000000, T: 672000, Avg. loss: 32789.124375\n",
            "Total training time: 1.55 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 99342.75, NNZs: 639, Bias: -1061.000000, T: 705600, Avg. loss: 33667.573423\n",
            "Total training time: 1.62 seconds.\n",
            "Convergence after 21 epochs took 1.62 seconds\n",
            "-- Epoch 1\n",
            "Norm: 26398.31, NNZs: 560, Bias: -34.000000, T: 33600, Avg. loss: 25361.617619\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 31613.19, NNZs: 570, Bias: -58.000000, T: 67200, Avg. loss: 22125.669107\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 36264.55, NNZs: 571, Bias: -73.000000, T: 100800, Avg. loss: 21133.352976\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 38909.07, NNZs: 576, Bias: -84.000000, T: 134400, Avg. loss: 20576.478393\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 41697.16, NNZs: 578, Bias: -98.000000, T: 168000, Avg. loss: 19900.769613\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 44398.44, NNZs: 581, Bias: -105.000000, T: 201600, Avg. loss: 20754.749137\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 46842.38, NNZs: 583, Bias: -118.000000, T: 235200, Avg. loss: 19517.157589\n",
            "Total training time: 0.61 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 49225.67, NNZs: 594, Bias: -128.000000, T: 268800, Avg. loss: 19386.208720\n",
            "Total training time: 0.67 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 51823.38, NNZs: 599, Bias: -137.000000, T: 302400, Avg. loss: 18184.694405\n",
            "Total training time: 0.76 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 54147.67, NNZs: 600, Bias: -143.000000, T: 336000, Avg. loss: 17881.692321\n",
            "Total training time: 0.83 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 56021.15, NNZs: 604, Bias: -148.000000, T: 369600, Avg. loss: 18653.010893\n",
            "Total training time: 0.89 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 58496.56, NNZs: 609, Bias: -153.000000, T: 403200, Avg. loss: 18471.054405\n",
            "Total training time: 0.98 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 59823.30, NNZs: 609, Bias: -163.000000, T: 436800, Avg. loss: 18384.287500\n",
            "Total training time: 1.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 61703.24, NNZs: 609, Bias: -173.000000, T: 470400, Avg. loss: 17105.853750\n",
            "Total training time: 1.13 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 63489.23, NNZs: 612, Bias: -181.000000, T: 504000, Avg. loss: 18975.412976\n",
            "Total training time: 1.20 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 65371.44, NNZs: 612, Bias: -186.000000, T: 537600, Avg. loss: 17669.717976\n",
            "Total training time: 1.26 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 66946.91, NNZs: 614, Bias: -194.000000, T: 571200, Avg. loss: 17663.917560\n",
            "Total training time: 1.38 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 68839.28, NNZs: 617, Bias: -203.000000, T: 604800, Avg. loss: 18486.346875\n",
            "Total training time: 1.49 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 70613.40, NNZs: 617, Bias: -213.000000, T: 638400, Avg. loss: 18157.243452\n",
            "Total training time: 1.59 seconds.\n",
            "Convergence after 19 epochs took 1.59 seconds\n",
            "-- Epoch 1\n",
            "Norm: 37314.14, NNZs: 631, Bias: -88.000000, T: 33600, Avg. loss: 96577.045923\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 44128.72, NNZs: 636, Bias: -162.000000, T: 67200, Avg. loss: 90873.737083\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 50583.74, NNZs: 642, Bias: -231.000000, T: 100800, Avg. loss: 89628.583750\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 54168.58, NNZs: 643, Bias: -302.000000, T: 134400, Avg. loss: 90226.199018\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 56510.36, NNZs: 643, Bias: -357.000000, T: 168000, Avg. loss: 86301.561548\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 62285.13, NNZs: 644, Bias: -425.000000, T: 201600, Avg. loss: 88602.669762\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 63389.29, NNZs: 644, Bias: -489.000000, T: 235200, Avg. loss: 87977.359286\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 66491.61, NNZs: 644, Bias: -556.000000, T: 268800, Avg. loss: 85774.638423\n",
            "Total training time: 0.60 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 69262.00, NNZs: 644, Bias: -609.000000, T: 302400, Avg. loss: 87651.091399\n",
            "Total training time: 0.70 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 71601.70, NNZs: 644, Bias: -668.000000, T: 336000, Avg. loss: 85173.424613\n",
            "Total training time: 0.77 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 74203.18, NNZs: 645, Bias: -723.000000, T: 369600, Avg. loss: 86586.834167\n",
            "Total training time: 0.84 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 75418.48, NNZs: 646, Bias: -781.000000, T: 403200, Avg. loss: 84865.833690\n",
            "Total training time: 0.91 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 76865.98, NNZs: 646, Bias: -832.000000, T: 436800, Avg. loss: 90802.518750\n",
            "Total training time: 0.98 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 78601.91, NNZs: 646, Bias: -887.000000, T: 470400, Avg. loss: 89849.372232\n",
            "Total training time: 1.03 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 81254.93, NNZs: 650, Bias: -951.000000, T: 504000, Avg. loss: 84589.548869\n",
            "Total training time: 1.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 82067.45, NNZs: 649, Bias: -1013.000000, T: 537600, Avg. loss: 88280.016190\n",
            "Total training time: 1.14 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 84184.62, NNZs: 650, Bias: -1075.000000, T: 571200, Avg. loss: 85966.068036\n",
            "Total training time: 1.20 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 85028.95, NNZs: 650, Bias: -1128.000000, T: 604800, Avg. loss: 88452.863333\n",
            "Total training time: 1.25 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 86305.68, NNZs: 650, Bias: -1185.000000, T: 638400, Avg. loss: 83922.722500\n",
            "Total training time: 1.30 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 87377.31, NNZs: 650, Bias: -1242.000000, T: 672000, Avg. loss: 87437.992798\n",
            "Total training time: 1.36 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 88789.49, NNZs: 654, Bias: -1291.000000, T: 705600, Avg. loss: 86266.221339\n",
            "Total training time: 1.41 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 89872.88, NNZs: 654, Bias: -1346.000000, T: 739200, Avg. loss: 84863.819226\n",
            "Total training time: 1.46 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 90691.38, NNZs: 655, Bias: -1392.000000, T: 772800, Avg. loss: 84192.695446\n",
            "Total training time: 1.51 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 92075.79, NNZs: 654, Bias: -1456.000000, T: 806400, Avg. loss: 89009.586488\n",
            "Total training time: 1.57 seconds.\n",
            "Convergence after 24 epochs took 1.57 seconds\n",
            "-- Epoch 1\n",
            "Norm: 35843.44, NNZs: 592, Bias: -183.000000, T: 33600, Avg. loss: 128480.352351\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 42126.43, NNZs: 601, Bias: -326.000000, T: 67200, Avg. loss: 129710.005357\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 47657.56, NNZs: 606, Bias: -466.000000, T: 100800, Avg. loss: 121485.599970\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 53381.81, NNZs: 608, Bias: -589.000000, T: 134400, Avg. loss: 124830.879792\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 57446.25, NNZs: 610, Bias: -717.000000, T: 168000, Avg. loss: 123217.713780\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 59583.12, NNZs: 610, Bias: -832.000000, T: 201600, Avg. loss: 124839.120506\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 61814.28, NNZs: 611, Bias: -969.000000, T: 235200, Avg. loss: 124496.203720\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 64293.43, NNZs: 611, Bias: -1105.000000, T: 268800, Avg. loss: 121835.435774\n",
            "Total training time: 0.44 seconds.\n",
            "Convergence after 8 epochs took 0.44 seconds\n",
            "-- Epoch 1\n",
            "Norm: 37641.17, NNZs: 632, Bias: -63.000000, T: 33600, Avg. loss: 80582.521369\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 45561.48, NNZs: 643, Bias: -110.000000, T: 67200, Avg. loss: 67452.582917\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 51531.62, NNZs: 657, Bias: -140.000000, T: 100800, Avg. loss: 65367.227470\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 56796.33, NNZs: 660, Bias: -176.000000, T: 134400, Avg. loss: 61077.277024\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 61779.10, NNZs: 661, Bias: -220.000000, T: 168000, Avg. loss: 62217.314673\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 66212.86, NNZs: 665, Bias: -257.000000, T: 201600, Avg. loss: 62441.151220\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 70281.72, NNZs: 665, Bias: -301.000000, T: 235200, Avg. loss: 60719.254881\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 73357.68, NNZs: 666, Bias: -339.000000, T: 268800, Avg. loss: 59862.561071\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 75843.56, NNZs: 668, Bias: -382.000000, T: 302400, Avg. loss: 59100.903899\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 78748.74, NNZs: 668, Bias: -416.000000, T: 336000, Avg. loss: 60639.541577\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 80260.03, NNZs: 668, Bias: -447.000000, T: 369600, Avg. loss: 59565.494315\n",
            "Total training time: 0.58 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 82765.54, NNZs: 668, Bias: -475.000000, T: 403200, Avg. loss: 58853.275179\n",
            "Total training time: 0.64 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 84879.71, NNZs: 668, Bias: -510.000000, T: 436800, Avg. loss: 60189.332113\n",
            "Total training time: 0.69 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 86717.81, NNZs: 668, Bias: -555.000000, T: 470400, Avg. loss: 59021.259107\n",
            "Total training time: 0.74 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 88321.25, NNZs: 668, Bias: -590.000000, T: 504000, Avg. loss: 60514.877024\n",
            "Total training time: 0.80 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 90614.48, NNZs: 670, Bias: -625.000000, T: 537600, Avg. loss: 58115.752589\n",
            "Total training time: 0.85 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 92847.08, NNZs: 670, Bias: -663.000000, T: 571200, Avg. loss: 60877.726012\n",
            "Total training time: 0.91 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 94550.09, NNZs: 671, Bias: -694.000000, T: 604800, Avg. loss: 57533.169613\n",
            "Total training time: 0.96 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 95684.10, NNZs: 671, Bias: -728.000000, T: 638400, Avg. loss: 59977.879911\n",
            "Total training time: 1.01 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 96928.58, NNZs: 671, Bias: -761.000000, T: 672000, Avg. loss: 60506.035565\n",
            "Total training time: 1.07 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 98871.28, NNZs: 671, Bias: -799.000000, T: 705600, Avg. loss: 57912.343601\n",
            "Total training time: 1.12 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 99679.73, NNZs: 671, Bias: -832.000000, T: 739200, Avg. loss: 60952.210387\n",
            "Total training time: 1.17 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 100897.16, NNZs: 672, Bias: -876.000000, T: 772800, Avg. loss: 61936.474762\n",
            "Total training time: 1.22 seconds.\n",
            "Convergence after 23 epochs took 1.22 seconds\n",
            "-- Epoch 1\n",
            "Norm: 42423.66, NNZs: 606, Bias: 27.000000, T: 33600, Avg. loss: 130188.282381\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 51881.43, NNZs: 619, Bias: 55.000000, T: 67200, Avg. loss: 119434.731429\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 57337.03, NNZs: 628, Bias: 90.000000, T: 100800, Avg. loss: 113136.772054\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 62414.69, NNZs: 639, Bias: 123.000000, T: 134400, Avg. loss: 113143.845446\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 68023.43, NNZs: 640, Bias: 158.000000, T: 168000, Avg. loss: 114112.914911\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 71561.46, NNZs: 641, Bias: 189.000000, T: 201600, Avg. loss: 111591.199643\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 75066.78, NNZs: 641, Bias: 217.000000, T: 235200, Avg. loss: 110774.543542\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 77962.25, NNZs: 641, Bias: 250.000000, T: 268800, Avg. loss: 109275.440357\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 81947.15, NNZs: 641, Bias: 277.000000, T: 302400, Avg. loss: 108801.517976\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 84724.58, NNZs: 641, Bias: 314.000000, T: 336000, Avg. loss: 110661.619821\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 87225.59, NNZs: 641, Bias: 354.000000, T: 369600, Avg. loss: 108303.698780\n",
            "Total training time: 0.61 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 89073.29, NNZs: 641, Bias: 389.000000, T: 403200, Avg. loss: 106832.891131\n",
            "Total training time: 0.67 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 91419.32, NNZs: 641, Bias: 416.000000, T: 436800, Avg. loss: 110941.566429\n",
            "Total training time: 0.72 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 93994.71, NNZs: 641, Bias: 456.000000, T: 470400, Avg. loss: 113329.592262\n",
            "Total training time: 0.78 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 95985.17, NNZs: 641, Bias: 495.000000, T: 504000, Avg. loss: 109959.708244\n",
            "Total training time: 0.83 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 97348.95, NNZs: 642, Bias: 524.000000, T: 537600, Avg. loss: 110222.617411\n",
            "Total training time: 0.89 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 99584.26, NNZs: 641, Bias: 554.000000, T: 571200, Avg. loss: 106344.273869\n",
            "Total training time: 0.94 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 101776.71, NNZs: 642, Bias: 584.000000, T: 604800, Avg. loss: 106643.082440\n",
            "Total training time: 0.99 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 103208.53, NNZs: 642, Bias: 613.000000, T: 638400, Avg. loss: 108343.745804\n",
            "Total training time: 1.05 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 105713.85, NNZs: 642, Bias: 639.000000, T: 672000, Avg. loss: 110997.620417\n",
            "Total training time: 1.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 107202.41, NNZs: 642, Bias: 672.000000, T: 705600, Avg. loss: 106189.241994\n",
            "Total training time: 1.15 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 109639.44, NNZs: 642, Bias: 698.000000, T: 739200, Avg. loss: 105599.439702\n",
            "Total training time: 1.21 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 110812.71, NNZs: 642, Bias: 732.000000, T: 772800, Avg. loss: 107623.893661\n",
            "Total training time: 1.26 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 112581.36, NNZs: 642, Bias: 765.000000, T: 806400, Avg. loss: 107060.136429\n",
            "Total training time: 1.31 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 114309.41, NNZs: 642, Bias: 798.000000, T: 840000, Avg. loss: 107680.858452\n",
            "Total training time: 1.37 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 116237.10, NNZs: 642, Bias: 826.000000, T: 873600, Avg. loss: 108127.371905\n",
            "Total training time: 1.42 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 117243.89, NNZs: 642, Bias: 861.000000, T: 907200, Avg. loss: 107025.967768\n",
            "Total training time: 1.48 seconds.\n",
            "Convergence after 27 epochs took 1.48 seconds\n",
            "-- Epoch 1\n",
            "Norm: 32486.64, NNZs: 577, Bias: -105.000000, T: 33600, Avg. loss: 61757.694315\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 40534.54, NNZs: 584, Bias: -200.000000, T: 67200, Avg. loss: 56512.068690\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 44742.80, NNZs: 588, Bias: -287.000000, T: 100800, Avg. loss: 56831.399375\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 48306.09, NNZs: 589, Bias: -365.000000, T: 134400, Avg. loss: 57471.921488\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 51911.01, NNZs: 594, Bias: -437.000000, T: 168000, Avg. loss: 53519.729940\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 54449.70, NNZs: 594, Bias: -512.000000, T: 201600, Avg. loss: 56500.563304\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 56208.93, NNZs: 594, Bias: -591.000000, T: 235200, Avg. loss: 55719.122857\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 58646.84, NNZs: 595, Bias: -667.000000, T: 268800, Avg. loss: 52715.723690\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 61872.61, NNZs: 600, Bias: -742.000000, T: 302400, Avg. loss: 54451.783214\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 64386.40, NNZs: 600, Bias: -819.000000, T: 336000, Avg. loss: 54228.641726\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 66294.61, NNZs: 600, Bias: -896.000000, T: 369600, Avg. loss: 52856.449167\n",
            "Total training time: 0.59 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 67818.78, NNZs: 600, Bias: -967.000000, T: 403200, Avg. loss: 52751.668839\n",
            "Total training time: 0.64 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 69092.91, NNZs: 600, Bias: -1041.000000, T: 436800, Avg. loss: 51681.258036\n",
            "Total training time: 0.69 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 71238.41, NNZs: 600, Bias: -1116.000000, T: 470400, Avg. loss: 51981.144881\n",
            "Total training time: 0.74 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 72874.40, NNZs: 600, Bias: -1189.000000, T: 504000, Avg. loss: 50819.850149\n",
            "Total training time: 0.80 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 74450.89, NNZs: 600, Bias: -1263.000000, T: 537600, Avg. loss: 53628.265268\n",
            "Total training time: 0.85 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 76487.74, NNZs: 601, Bias: -1337.000000, T: 571200, Avg. loss: 52789.735744\n",
            "Total training time: 0.90 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 77849.43, NNZs: 603, Bias: -1410.000000, T: 604800, Avg. loss: 52466.989940\n",
            "Total training time: 0.96 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 79984.11, NNZs: 603, Bias: -1479.000000, T: 638400, Avg. loss: 53286.368958\n",
            "Total training time: 1.01 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 80396.01, NNZs: 603, Bias: -1550.000000, T: 672000, Avg. loss: 51882.202679\n",
            "Total training time: 1.06 seconds.\n",
            "Convergence after 20 epochs took 1.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 32589.46, NNZs: 583, Bias: -17.000000, T: 33600, Avg. loss: 62025.632560\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 37511.93, NNZs: 609, Bias: -29.000000, T: 67200, Avg. loss: 58115.097619\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 42262.38, NNZs: 613, Bias: -45.000000, T: 100800, Avg. loss: 57995.263839\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 46423.57, NNZs: 620, Bias: -57.000000, T: 134400, Avg. loss: 58623.844851\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 50025.21, NNZs: 622, Bias: -63.000000, T: 168000, Avg. loss: 53911.482560\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 53211.32, NNZs: 620, Bias: -77.000000, T: 201600, Avg. loss: 51937.196726\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 56199.23, NNZs: 624, Bias: -82.000000, T: 235200, Avg. loss: 54733.387946\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 58992.86, NNZs: 625, Bias: -103.000000, T: 268800, Avg. loss: 52753.839226\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 61704.82, NNZs: 627, Bias: -111.000000, T: 302400, Avg. loss: 55863.080506\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 63877.60, NNZs: 632, Bias: -131.000000, T: 336000, Avg. loss: 54647.428988\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 66299.11, NNZs: 634, Bias: -148.000000, T: 369600, Avg. loss: 54471.431637\n",
            "Total training time: 0.60 seconds.\n",
            "Convergence after 11 epochs took 0.60 seconds\n",
            "-- Epoch 1\n",
            "Norm: 41758.03, NNZs: 625, Bias: -462.000000, T: 33600, Avg. loss: 233095.000774\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 50310.57, NNZs: 631, Bias: -882.000000, T: 67200, Avg. loss: 228599.348750\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 56368.42, NNZs: 641, Bias: -1299.000000, T: 100800, Avg. loss: 227184.443333\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 60403.37, NNZs: 645, Bias: -1688.000000, T: 134400, Avg. loss: 229155.082083\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 63372.61, NNZs: 649, Bias: -2067.000000, T: 168000, Avg. loss: 221451.627738\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 67369.73, NNZs: 650, Bias: -2466.000000, T: 201600, Avg. loss: 225979.830327\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 70718.75, NNZs: 650, Bias: -2852.000000, T: 235200, Avg. loss: 225628.723304\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 71812.83, NNZs: 651, Bias: -3252.000000, T: 268800, Avg. loss: 226431.173661\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 73696.43, NNZs: 653, Bias: -3628.000000, T: 302400, Avg. loss: 223407.070655\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 76871.33, NNZs: 653, Bias: -3996.000000, T: 336000, Avg. loss: 223646.291935\n",
            "Total training time: 0.56 seconds.\n",
            "Convergence after 10 epochs took 0.56 seconds\n",
            "-- Epoch 1\n",
            "Norm: 36290.84, NNZs: 625, Bias: -187.000000, T: 33600, Avg. loss: 159959.056161\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 44920.30, NNZs: 641, Bias: -378.000000, T: 67200, Avg. loss: 154155.718125\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 51342.61, NNZs: 651, Bias: -555.000000, T: 100800, Avg. loss: 150645.519911\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 56524.62, NNZs: 652, Bias: -729.000000, T: 134400, Avg. loss: 146213.910208\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 59759.74, NNZs: 652, Bias: -916.000000, T: 168000, Avg. loss: 150237.405774\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 63784.97, NNZs: 652, Bias: -1087.000000, T: 201600, Avg. loss: 147086.445833\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 65860.29, NNZs: 653, Bias: -1268.000000, T: 235200, Avg. loss: 149149.701250\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 67339.26, NNZs: 656, Bias: -1434.000000, T: 268800, Avg. loss: 150210.671667\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 69460.15, NNZs: 656, Bias: -1616.000000, T: 302400, Avg. loss: 147811.250506\n",
            "Total training time: 0.50 seconds.\n",
            "Convergence after 9 epochs took 0.50 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.7s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm_slp)\n",
        "print(clas_rep_slp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inVKubD5v3Ux",
        "outputId": "5f793e67-25e7-4899-ace7-7575eed5b517"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[741   1   4   0   0  10  22   0   7   0]\n",
            " [  0 895   8   6   1   3   2   0  34   0]\n",
            " [  4   3 710  28   2   9  18   4  59   1]\n",
            " [  6   2  23 742   2  38   4   5  28   8]\n",
            " [  5   6  33   2 689   2  12   6  28  13]\n",
            " [ 12   5   4  38   3 654  21   1  58   4]\n",
            " [  3   1  12   0   0  18 823   1  12   0]\n",
            " [  4   5  32   1   2   6   0 781  15  14]\n",
            " [  6  11  15   8   2  25  10   5 732   3]\n",
            " [  5   2  37  14  62  30   0  85  82 510]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94       785\n",
            "           1       0.96      0.94      0.95       949\n",
            "           2       0.81      0.85      0.83       838\n",
            "           3       0.88      0.86      0.87       858\n",
            "           4       0.90      0.87      0.88       796\n",
            "           5       0.82      0.82      0.82       800\n",
            "           6       0.90      0.95      0.92       870\n",
            "           7       0.88      0.91      0.89       860\n",
            "           8       0.69      0.90      0.78       817\n",
            "           9       0.92      0.62      0.74       827\n",
            "\n",
            "    accuracy                           0.87      8400\n",
            "   macro avg       0.87      0.86      0.86      8400\n",
            "weighted avg       0.87      0.87      0.87      8400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per.coef_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF73wZUpwQzA",
        "outputId": "3f0599b6-a1b4-4dc1-b270-8e1d2a4277a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bias and intercept are used interchangeably.\n",
        "per.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1TjOs79wUcx",
        "outputId": "c9c02096-378f-41f0-9a13-1ee042b26ad2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1061.,  -213., -1456., -1105.,  -876.,   861., -1550.,  -148.,\n",
              "       -3996., -1616.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16), verbose=1, random_state=123)\n",
        "mlp.fit(x_train,y_train)\n",
        "preds_mlp = mlp.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO216n0Gwkce",
        "outputId": "71522af7-78ed-40f0-acca-96639dddf856"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 3.94169702\n",
            "Iteration 2, loss = 1.35736435\n",
            "Iteration 3, loss = 1.01940349\n",
            "Iteration 4, loss = 0.84244621\n",
            "Iteration 5, loss = 0.73913542\n",
            "Iteration 6, loss = 0.67797245\n",
            "Iteration 7, loss = 0.64415324\n",
            "Iteration 8, loss = 0.61427454\n",
            "Iteration 9, loss = 0.58410470\n",
            "Iteration 10, loss = 0.55879376\n",
            "Iteration 11, loss = 0.49215218\n",
            "Iteration 12, loss = 0.45592746\n",
            "Iteration 13, loss = 0.42851116\n",
            "Iteration 14, loss = 0.40318218\n",
            "Iteration 15, loss = 0.38689829\n",
            "Iteration 16, loss = 0.37453476\n",
            "Iteration 17, loss = 0.35740677\n",
            "Iteration 18, loss = 0.34135945\n",
            "Iteration 19, loss = 0.33477586\n",
            "Iteration 20, loss = 0.32580908\n",
            "Iteration 21, loss = 0.31523972\n",
            "Iteration 22, loss = 0.30116722\n",
            "Iteration 23, loss = 0.29136387\n",
            "Iteration 24, loss = 0.28558646\n",
            "Iteration 25, loss = 0.27735506\n",
            "Iteration 26, loss = 0.27266574\n",
            "Iteration 27, loss = 0.27062563\n",
            "Iteration 28, loss = 0.25933873\n",
            "Iteration 29, loss = 0.25196397\n",
            "Iteration 30, loss = 0.25438021\n",
            "Iteration 31, loss = 0.24328995\n",
            "Iteration 32, loss = 0.24399618\n",
            "Iteration 33, loss = 0.23453967\n",
            "Iteration 34, loss = 0.23132086\n",
            "Iteration 35, loss = 0.22676267\n",
            "Iteration 36, loss = 0.22078195\n",
            "Iteration 37, loss = 0.21696620\n",
            "Iteration 38, loss = 0.21337956\n",
            "Iteration 39, loss = 0.20823267\n",
            "Iteration 40, loss = 0.20978789\n",
            "Iteration 41, loss = 0.20209105\n",
            "Iteration 42, loss = 0.19770587\n",
            "Iteration 43, loss = 0.19481024\n",
            "Iteration 44, loss = 0.19276436\n",
            "Iteration 45, loss = 0.19169770\n",
            "Iteration 46, loss = 0.19066757\n",
            "Iteration 47, loss = 0.18458619\n",
            "Iteration 48, loss = 0.18958932\n",
            "Iteration 49, loss = 0.18204181\n",
            "Iteration 50, loss = 0.17564605\n",
            "Iteration 51, loss = 0.17630937\n",
            "Iteration 52, loss = 0.17420407\n",
            "Iteration 53, loss = 0.17346055\n",
            "Iteration 54, loss = 0.16943218\n",
            "Iteration 55, loss = 0.16768900\n",
            "Iteration 56, loss = 0.16901477\n",
            "Iteration 57, loss = 0.16547307\n",
            "Iteration 58, loss = 0.16488096\n",
            "Iteration 59, loss = 0.16360354\n",
            "Iteration 60, loss = 0.16260132\n",
            "Iteration 61, loss = 0.16323705\n",
            "Iteration 62, loss = 0.15705840\n",
            "Iteration 63, loss = 0.15601808\n",
            "Iteration 64, loss = 0.15460566\n",
            "Iteration 65, loss = 0.15354200\n",
            "Iteration 66, loss = 0.15224909\n",
            "Iteration 67, loss = 0.15341591\n",
            "Iteration 68, loss = 0.14826479\n",
            "Iteration 69, loss = 0.14955273\n",
            "Iteration 70, loss = 0.15122006\n",
            "Iteration 71, loss = 0.14955421\n",
            "Iteration 72, loss = 0.14662363\n",
            "Iteration 73, loss = 0.14731315\n",
            "Iteration 74, loss = 0.14305328\n",
            "Iteration 75, loss = 0.13920685\n",
            "Iteration 76, loss = 0.14030536\n",
            "Iteration 77, loss = 0.13667289\n",
            "Iteration 78, loss = 0.13876935\n",
            "Iteration 79, loss = 0.13840778\n",
            "Iteration 80, loss = 0.14185471\n",
            "Iteration 81, loss = 0.13678128\n",
            "Iteration 82, loss = 0.13804593\n",
            "Iteration 83, loss = 0.13644490\n",
            "Iteration 84, loss = 0.13468615\n",
            "Iteration 85, loss = 0.13827752\n",
            "Iteration 86, loss = 0.13185166\n",
            "Iteration 87, loss = 0.13145476\n",
            "Iteration 88, loss = 0.13425805\n",
            "Iteration 89, loss = 0.13298520\n",
            "Iteration 90, loss = 0.13132257\n",
            "Iteration 91, loss = 0.12807984\n",
            "Iteration 92, loss = 0.12753875\n",
            "Iteration 93, loss = 0.12837881\n",
            "Iteration 94, loss = 0.12949357\n",
            "Iteration 95, loss = 0.13017012\n",
            "Iteration 96, loss = 0.12281812\n",
            "Iteration 97, loss = 0.12743928\n",
            "Iteration 98, loss = 0.12218498\n",
            "Iteration 99, loss = 0.12368445\n",
            "Iteration 100, loss = 0.12433870\n",
            "Iteration 101, loss = 0.12279434\n",
            "Iteration 102, loss = 0.12555607\n",
            "Iteration 103, loss = 0.12366438\n",
            "Iteration 104, loss = 0.12165481\n",
            "Iteration 105, loss = 0.12101863\n",
            "Iteration 106, loss = 0.12036811\n",
            "Iteration 107, loss = 0.12513062\n",
            "Iteration 108, loss = 0.12509694\n",
            "Iteration 109, loss = 0.12041080\n",
            "Iteration 110, loss = 0.11948783\n",
            "Iteration 111, loss = 0.12024055\n",
            "Iteration 112, loss = 0.11532398\n",
            "Iteration 113, loss = 0.11594256\n",
            "Iteration 114, loss = 0.11617000\n",
            "Iteration 115, loss = 0.11538524\n",
            "Iteration 116, loss = 0.11299358\n",
            "Iteration 117, loss = 0.11500318\n",
            "Iteration 118, loss = 0.11409552\n",
            "Iteration 119, loss = 0.11904145\n",
            "Iteration 120, loss = 0.11494611\n",
            "Iteration 121, loss = 0.11675679\n",
            "Iteration 122, loss = 0.11599591\n",
            "Iteration 123, loss = 0.11113465\n",
            "Iteration 124, loss = 0.11304816\n",
            "Iteration 125, loss = 0.11172631\n",
            "Iteration 126, loss = 0.11271302\n",
            "Iteration 127, loss = 0.11467463\n",
            "Iteration 128, loss = 0.10980898\n",
            "Iteration 129, loss = 0.11465944\n",
            "Iteration 130, loss = 0.11081979\n",
            "Iteration 131, loss = 0.11007925\n",
            "Iteration 132, loss = 0.11337016\n",
            "Iteration 133, loss = 0.10791442\n",
            "Iteration 134, loss = 0.11151077\n",
            "Iteration 135, loss = 0.10795403\n",
            "Iteration 136, loss = 0.10969652\n",
            "Iteration 137, loss = 0.10761164\n",
            "Iteration 138, loss = 0.10572626\n",
            "Iteration 139, loss = 0.10849381\n",
            "Iteration 140, loss = 0.10706207\n",
            "Iteration 141, loss = 0.11154011\n",
            "Iteration 142, loss = 0.10432369\n",
            "Iteration 143, loss = 0.10993983\n",
            "Iteration 144, loss = 0.10379039\n",
            "Iteration 145, loss = 0.10577729\n",
            "Iteration 146, loss = 0.10336161\n",
            "Iteration 147, loss = 0.10488500\n",
            "Iteration 148, loss = 0.10751327\n",
            "Iteration 149, loss = 0.10441984\n",
            "Iteration 150, loss = 0.10330453\n",
            "Iteration 151, loss = 0.11215383\n",
            "Iteration 152, loss = 0.10253060\n",
            "Iteration 153, loss = 0.10221656\n",
            "Iteration 154, loss = 0.10280510\n",
            "Iteration 155, loss = 0.10016155\n",
            "Iteration 156, loss = 0.09824809\n",
            "Iteration 157, loss = 0.09978988\n",
            "Iteration 158, loss = 0.10307896\n",
            "Iteration 159, loss = 0.10592160\n",
            "Iteration 160, loss = 0.10193593\n",
            "Iteration 161, loss = 0.10366555\n",
            "Iteration 162, loss = 0.10338276\n",
            "Iteration 163, loss = 0.10173444\n",
            "Iteration 164, loss = 0.09895412\n",
            "Iteration 165, loss = 0.09609300\n",
            "Iteration 166, loss = 0.09597913\n",
            "Iteration 167, loss = 0.10271442\n",
            "Iteration 168, loss = 0.10081375\n",
            "Iteration 169, loss = 0.09911258\n",
            "Iteration 170, loss = 0.10124273\n",
            "Iteration 171, loss = 0.10110217\n",
            "Iteration 172, loss = 0.09904597\n",
            "Iteration 173, loss = 0.09426717\n",
            "Iteration 174, loss = 0.09511039\n",
            "Iteration 175, loss = 0.10011610\n",
            "Iteration 176, loss = 0.09978317\n",
            "Iteration 177, loss = 0.10074915\n",
            "Iteration 178, loss = 0.10286360\n",
            "Iteration 179, loss = 0.09765973\n",
            "Iteration 180, loss = 0.09730910\n",
            "Iteration 181, loss = 0.09508308\n",
            "Iteration 182, loss = 0.09599899\n",
            "Iteration 183, loss = 0.09409585\n",
            "Iteration 184, loss = 0.09580055\n",
            "Iteration 185, loss = 0.09692190\n",
            "Iteration 186, loss = 0.09229838\n",
            "Iteration 187, loss = 0.09154846\n",
            "Iteration 188, loss = 0.09220859\n",
            "Iteration 189, loss = 0.09516103\n",
            "Iteration 190, loss = 0.09708804\n",
            "Iteration 191, loss = 0.09893675\n",
            "Iteration 192, loss = 0.09746285\n",
            "Iteration 193, loss = 0.09054500\n",
            "Iteration 194, loss = 0.08953760\n",
            "Iteration 195, loss = 0.08951153\n",
            "Iteration 196, loss = 0.09545902\n",
            "Iteration 197, loss = 0.09140987\n",
            "Iteration 198, loss = 0.09318657\n",
            "Iteration 199, loss = 0.09785040\n",
            "Iteration 200, loss = 0.09125465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_mlp = confusion_matrix(y_test, preds_mlp)\n",
        "class_rep_mlp = classification_report(y_test, preds_mlp)\n",
        "print(cm_mlp)\n",
        "print(class_rep_mlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlWZfLZ6wqK3",
        "outputId": "22fd3212-e551-4ac2-bd73-d949240061d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[757   0   6   1   2   4   6   0   8   1]\n",
            " [  0 918  10   6   1   2   4   0   8   0]\n",
            " [ 11   2 778   9   6   4  11   3  14   0]\n",
            " [  2   6  35 775   0   8   2  12  13   5]\n",
            " [  1   5   1   2 741   3  13   1  10  19]\n",
            " [  5   1   7  35   0 717  14   1  15   5]\n",
            " [  6   6   3   0   7  12 825   0  10   1]\n",
            " [  3   7  18  14   5   2   0 790   2  19]\n",
            " [ 12  15  13  20   3   7  10   3 723  11]\n",
            " [  6   1   0  14  39   9   0  23  11 724]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       785\n",
            "           1       0.96      0.97      0.96       949\n",
            "           2       0.89      0.93      0.91       838\n",
            "           3       0.88      0.90      0.89       858\n",
            "           4       0.92      0.93      0.93       796\n",
            "           5       0.93      0.90      0.91       800\n",
            "           6       0.93      0.95      0.94       870\n",
            "           7       0.95      0.92      0.93       860\n",
            "           8       0.89      0.88      0.89       817\n",
            "           9       0.92      0.88      0.90       827\n",
            "\n",
            "    accuracy                           0.92      8400\n",
            "   macro avg       0.92      0.92      0.92      8400\n",
            "weighted avg       0.92      0.92      0.92      8400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.losses import  CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Va4HNLwaxB_A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tc = to_categorical(y_train)\n",
        "y_test_tc = to_categorical(y_test)\n",
        "\n",
        "print(y_train_tc.shape)\n",
        "print(y_test_tc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI5gb0nbxE5u",
        "outputId": "25baef75-657b-42e9-b2ee-4dfbf586e4ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33600, 10)\n",
            "(8400, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=(784)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoU3uPA5xKbW",
        "outputId": "6b3ef691-b87a-4100-d391-08f6466be2fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 335,114\n",
            "Trainable params: 335,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gybT-pJRxPQI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train_tc, validation_data=(x_test,y_test_tc),epochs=100,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Tu04ldxWRH",
        "outputId": "4c3a9a1c-8eb4-4d7a-bcea-8e02aa45ad7b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 - 10s - loss: 2.4784 - accuracy: 0.7705 - val_loss: 0.3556 - val_accuracy: 0.9081 - 10s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "1050/1050 - 9s - loss: 0.4463 - accuracy: 0.8794 - val_loss: 0.2523 - val_accuracy: 0.9298 - 9s/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "1050/1050 - 7s - loss: 0.3375 - accuracy: 0.9065 - val_loss: 0.2216 - val_accuracy: 0.9379 - 7s/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "1050/1050 - 6s - loss: 0.3136 - accuracy: 0.9168 - val_loss: 0.2364 - val_accuracy: 0.9349 - 6s/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "1050/1050 - 6s - loss: 0.2737 - accuracy: 0.9263 - val_loss: 0.1983 - val_accuracy: 0.9442 - 6s/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "1050/1050 - 8s - loss: 0.2718 - accuracy: 0.9299 - val_loss: 0.1950 - val_accuracy: 0.9480 - 8s/epoch - 7ms/step\n",
            "Epoch 7/100\n",
            "1050/1050 - 5s - loss: 0.2447 - accuracy: 0.9374 - val_loss: 0.1988 - val_accuracy: 0.9511 - 5s/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "1050/1050 - 5s - loss: 0.2376 - accuracy: 0.9391 - val_loss: 0.2275 - val_accuracy: 0.9477 - 5s/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "1050/1050 - 5s - loss: 0.2406 - accuracy: 0.9400 - val_loss: 0.1837 - val_accuracy: 0.9613 - 5s/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "1050/1050 - 5s - loss: 0.2105 - accuracy: 0.9475 - val_loss: 0.1815 - val_accuracy: 0.9560 - 5s/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "1050/1050 - 5s - loss: 0.2136 - accuracy: 0.9471 - val_loss: 0.2145 - val_accuracy: 0.9582 - 5s/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "1050/1050 - 8s - loss: 0.2074 - accuracy: 0.9495 - val_loss: 0.1740 - val_accuracy: 0.9608 - 8s/epoch - 8ms/step\n",
            "Epoch 13/100\n",
            "1050/1050 - 8s - loss: 0.1870 - accuracy: 0.9538 - val_loss: 0.1947 - val_accuracy: 0.9595 - 8s/epoch - 8ms/step\n",
            "Epoch 14/100\n",
            "1050/1050 - 7s - loss: 0.1801 - accuracy: 0.9554 - val_loss: 0.1762 - val_accuracy: 0.9671 - 7s/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "1050/1050 - 5s - loss: 0.1845 - accuracy: 0.9567 - val_loss: 0.2208 - val_accuracy: 0.9632 - 5s/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "1050/1050 - 7s - loss: 0.1773 - accuracy: 0.9582 - val_loss: 0.2348 - val_accuracy: 0.9663 - 7s/epoch - 7ms/step\n",
            "Epoch 17/100\n",
            "1050/1050 - 7s - loss: 0.1736 - accuracy: 0.9587 - val_loss: 0.2038 - val_accuracy: 0.9674 - 7s/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "1050/1050 - 5s - loss: 0.1571 - accuracy: 0.9605 - val_loss: 0.2029 - val_accuracy: 0.9652 - 5s/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "1050/1050 - 5s - loss: 0.1747 - accuracy: 0.9586 - val_loss: 0.2385 - val_accuracy: 0.9642 - 5s/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "1050/1050 - 5s - loss: 0.1571 - accuracy: 0.9626 - val_loss: 0.2207 - val_accuracy: 0.9663 - 5s/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "1050/1050 - 5s - loss: 0.1609 - accuracy: 0.9618 - val_loss: 0.2169 - val_accuracy: 0.9664 - 5s/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "1050/1050 - 5s - loss: 0.1648 - accuracy: 0.9623 - val_loss: 0.2035 - val_accuracy: 0.9681 - 5s/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "1050/1050 - 5s - loss: 0.1561 - accuracy: 0.9631 - val_loss: 0.2173 - val_accuracy: 0.9662 - 5s/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "1050/1050 - 5s - loss: 0.1530 - accuracy: 0.9644 - val_loss: 0.2526 - val_accuracy: 0.9606 - 5s/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "1050/1050 - 5s - loss: 0.1609 - accuracy: 0.9625 - val_loss: 0.3142 - val_accuracy: 0.9660 - 5s/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "1050/1050 - 5s - loss: 0.1554 - accuracy: 0.9662 - val_loss: 0.2124 - val_accuracy: 0.9700 - 5s/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "1050/1050 - 5s - loss: 0.1566 - accuracy: 0.9643 - val_loss: 0.2199 - val_accuracy: 0.9665 - 5s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "1050/1050 - 5s - loss: 0.1612 - accuracy: 0.9634 - val_loss: 0.2359 - val_accuracy: 0.9677 - 5s/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "1050/1050 - 5s - loss: 0.1387 - accuracy: 0.9667 - val_loss: 0.2534 - val_accuracy: 0.9688 - 5s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "1050/1050 - 5s - loss: 0.1512 - accuracy: 0.9657 - val_loss: 0.3038 - val_accuracy: 0.9636 - 5s/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "1050/1050 - 5s - loss: 0.1540 - accuracy: 0.9664 - val_loss: 0.2821 - val_accuracy: 0.9696 - 5s/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "1050/1050 - 5s - loss: 0.1552 - accuracy: 0.9671 - val_loss: 0.2177 - val_accuracy: 0.9713 - 5s/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "1050/1050 - 5s - loss: 0.1366 - accuracy: 0.9684 - val_loss: 0.2433 - val_accuracy: 0.9723 - 5s/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "1050/1050 - 5s - loss: 0.1379 - accuracy: 0.9683 - val_loss: 0.2613 - val_accuracy: 0.9655 - 5s/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "1050/1050 - 7s - loss: 0.1472 - accuracy: 0.9683 - val_loss: 0.2528 - val_accuracy: 0.9681 - 7s/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "1050/1050 - 5s - loss: 0.1475 - accuracy: 0.9693 - val_loss: 0.3076 - val_accuracy: 0.9689 - 5s/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "1050/1050 - 6s - loss: 0.1353 - accuracy: 0.9709 - val_loss: 0.3441 - val_accuracy: 0.9686 - 6s/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "1050/1050 - 5s - loss: 0.1369 - accuracy: 0.9717 - val_loss: 0.3133 - val_accuracy: 0.9685 - 5s/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "1050/1050 - 5s - loss: 0.1392 - accuracy: 0.9690 - val_loss: 0.2926 - val_accuracy: 0.9712 - 5s/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "1050/1050 - 5s - loss: 0.1315 - accuracy: 0.9704 - val_loss: 0.2926 - val_accuracy: 0.9695 - 5s/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "1050/1050 - 5s - loss: 0.1334 - accuracy: 0.9707 - val_loss: 0.2349 - val_accuracy: 0.9692 - 5s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "1050/1050 - 5s - loss: 0.1523 - accuracy: 0.9689 - val_loss: 0.2662 - val_accuracy: 0.9654 - 5s/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "1050/1050 - 5s - loss: 0.1336 - accuracy: 0.9709 - val_loss: 0.3493 - val_accuracy: 0.9677 - 5s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "1050/1050 - 5s - loss: 0.1510 - accuracy: 0.9701 - val_loss: 0.3108 - val_accuracy: 0.9698 - 5s/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "1050/1050 - 5s - loss: 0.1193 - accuracy: 0.9742 - val_loss: 0.3546 - val_accuracy: 0.9713 - 5s/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "1050/1050 - 5s - loss: 0.1399 - accuracy: 0.9706 - val_loss: 0.3099 - val_accuracy: 0.9699 - 5s/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "1050/1050 - 6s - loss: 0.1439 - accuracy: 0.9695 - val_loss: 0.2875 - val_accuracy: 0.9713 - 6s/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "1050/1050 - 5s - loss: 0.1455 - accuracy: 0.9701 - val_loss: 0.3015 - val_accuracy: 0.9690 - 5s/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "1050/1050 - 5s - loss: 0.1330 - accuracy: 0.9710 - val_loss: 0.3736 - val_accuracy: 0.9704 - 5s/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "1050/1050 - 5s - loss: 0.1400 - accuracy: 0.9725 - val_loss: 0.3444 - val_accuracy: 0.9654 - 5s/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "1050/1050 - 5s - loss: 0.1325 - accuracy: 0.9721 - val_loss: 0.3935 - val_accuracy: 0.9702 - 5s/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "1050/1050 - 5s - loss: 0.1342 - accuracy: 0.9721 - val_loss: 0.4429 - val_accuracy: 0.9696 - 5s/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "1050/1050 - 5s - loss: 0.1424 - accuracy: 0.9716 - val_loss: 0.3334 - val_accuracy: 0.9690 - 5s/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "1050/1050 - 5s - loss: 0.1192 - accuracy: 0.9753 - val_loss: 0.3681 - val_accuracy: 0.9702 - 5s/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "1050/1050 - 5s - loss: 0.1242 - accuracy: 0.9740 - val_loss: 0.3085 - val_accuracy: 0.9715 - 5s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "1050/1050 - 5s - loss: 0.1195 - accuracy: 0.9743 - val_loss: 0.4755 - val_accuracy: 0.9670 - 5s/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "1050/1050 - 5s - loss: 0.1665 - accuracy: 0.9705 - val_loss: 0.3351 - val_accuracy: 0.9700 - 5s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "1050/1050 - 5s - loss: 0.1425 - accuracy: 0.9715 - val_loss: 0.3138 - val_accuracy: 0.9685 - 5s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "1050/1050 - 5s - loss: 0.1361 - accuracy: 0.9732 - val_loss: 0.4390 - val_accuracy: 0.9705 - 5s/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "1050/1050 - 5s - loss: 0.1422 - accuracy: 0.9718 - val_loss: 0.4041 - val_accuracy: 0.9696 - 5s/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "1050/1050 - 5s - loss: 0.1206 - accuracy: 0.9746 - val_loss: 0.4284 - val_accuracy: 0.9702 - 5s/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "1050/1050 - 5s - loss: 0.1320 - accuracy: 0.9733 - val_loss: 0.4057 - val_accuracy: 0.9710 - 5s/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "1050/1050 - 5s - loss: 0.1365 - accuracy: 0.9725 - val_loss: 0.4074 - val_accuracy: 0.9713 - 5s/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "1050/1050 - 5s - loss: 0.1158 - accuracy: 0.9751 - val_loss: 0.4025 - val_accuracy: 0.9683 - 5s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "1050/1050 - 5s - loss: 0.1376 - accuracy: 0.9725 - val_loss: 0.4861 - val_accuracy: 0.9736 - 5s/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "1050/1050 - 5s - loss: 0.1403 - accuracy: 0.9731 - val_loss: 0.3937 - val_accuracy: 0.9715 - 5s/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "1050/1050 - 5s - loss: 0.1145 - accuracy: 0.9760 - val_loss: 0.3620 - val_accuracy: 0.9673 - 5s/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "1050/1050 - 5s - loss: 0.1086 - accuracy: 0.9784 - val_loss: 0.4246 - val_accuracy: 0.9724 - 5s/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "1050/1050 - 5s - loss: 0.1283 - accuracy: 0.9740 - val_loss: 0.3422 - val_accuracy: 0.9733 - 5s/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "1050/1050 - 5s - loss: 0.1122 - accuracy: 0.9754 - val_loss: 0.4083 - val_accuracy: 0.9719 - 5s/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "1050/1050 - 5s - loss: 0.1535 - accuracy: 0.9727 - val_loss: 0.3769 - val_accuracy: 0.9677 - 5s/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "1050/1050 - 5s - loss: 0.1503 - accuracy: 0.9710 - val_loss: 0.4149 - val_accuracy: 0.9717 - 5s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "1050/1050 - 5s - loss: 0.1234 - accuracy: 0.9747 - val_loss: 0.3924 - val_accuracy: 0.9721 - 5s/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "1050/1050 - 5s - loss: 0.1472 - accuracy: 0.9737 - val_loss: 0.5615 - val_accuracy: 0.9705 - 5s/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "1050/1050 - 5s - loss: 0.1569 - accuracy: 0.9715 - val_loss: 0.4417 - val_accuracy: 0.9725 - 5s/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "1050/1050 - 5s - loss: 0.1367 - accuracy: 0.9723 - val_loss: 0.4237 - val_accuracy: 0.9710 - 5s/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "1050/1050 - 5s - loss: 0.1353 - accuracy: 0.9733 - val_loss: 0.3565 - val_accuracy: 0.9711 - 5s/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "1050/1050 - 5s - loss: 0.1347 - accuracy: 0.9745 - val_loss: 0.5482 - val_accuracy: 0.9730 - 5s/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "1050/1050 - 5s - loss: 0.1097 - accuracy: 0.9768 - val_loss: 0.4999 - val_accuracy: 0.9704 - 5s/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "1050/1050 - 5s - loss: 0.1294 - accuracy: 0.9735 - val_loss: 0.6102 - val_accuracy: 0.9718 - 5s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "1050/1050 - 5s - loss: 0.1280 - accuracy: 0.9740 - val_loss: 0.5181 - val_accuracy: 0.9710 - 5s/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "1050/1050 - 5s - loss: 0.1348 - accuracy: 0.9723 - val_loss: 0.4584 - val_accuracy: 0.9707 - 5s/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "1050/1050 - 5s - loss: 0.1484 - accuracy: 0.9726 - val_loss: 0.4093 - val_accuracy: 0.9695 - 5s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "1050/1050 - 5s - loss: 0.1217 - accuracy: 0.9742 - val_loss: 0.5258 - val_accuracy: 0.9688 - 5s/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "1050/1050 - 5s - loss: 0.1365 - accuracy: 0.9730 - val_loss: 0.5549 - val_accuracy: 0.9610 - 5s/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "1050/1050 - 5s - loss: 0.1306 - accuracy: 0.9735 - val_loss: 0.6080 - val_accuracy: 0.9676 - 5s/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "1050/1050 - 5s - loss: 0.1369 - accuracy: 0.9733 - val_loss: 0.4698 - val_accuracy: 0.9679 - 5s/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "1050/1050 - 5s - loss: 0.1470 - accuracy: 0.9729 - val_loss: 0.4601 - val_accuracy: 0.9696 - 5s/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "1050/1050 - 5s - loss: 0.1602 - accuracy: 0.9699 - val_loss: 0.5293 - val_accuracy: 0.9650 - 5s/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "1050/1050 - 5s - loss: 0.1598 - accuracy: 0.9708 - val_loss: 0.6997 - val_accuracy: 0.9698 - 5s/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "1050/1050 - 6s - loss: 0.1553 - accuracy: 0.9716 - val_loss: 0.5960 - val_accuracy: 0.9690 - 6s/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "1050/1050 - 5s - loss: 0.1492 - accuracy: 0.9749 - val_loss: 0.8229 - val_accuracy: 0.9657 - 5s/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "1050/1050 - 5s - loss: 0.1698 - accuracy: 0.9737 - val_loss: 0.5987 - val_accuracy: 0.9680 - 5s/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "1050/1050 - 6s - loss: 0.1439 - accuracy: 0.9719 - val_loss: 0.4642 - val_accuracy: 0.9698 - 6s/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "1050/1050 - 5s - loss: 0.1744 - accuracy: 0.9709 - val_loss: 0.5757 - val_accuracy: 0.9688 - 5s/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "1050/1050 - 5s - loss: 0.1569 - accuracy: 0.9745 - val_loss: 0.6743 - val_accuracy: 0.9611 - 5s/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "1050/1050 - 5s - loss: 0.1458 - accuracy: 0.9751 - val_loss: 0.5677 - val_accuracy: 0.9701 - 5s/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "1050/1050 - 5s - loss: 0.1526 - accuracy: 0.9740 - val_loss: 0.6489 - val_accuracy: 0.9639 - 5s/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "1050/1050 - 5s - loss: 0.1474 - accuracy: 0.9712 - val_loss: 0.7101 - val_accuracy: 0.9690 - 5s/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "1050/1050 - 5s - loss: 0.1379 - accuracy: 0.9722 - val_loss: 0.4448 - val_accuracy: 0.9657 - 5s/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  \"Accuracy\"\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# \"Loss\"\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "dZfgaJtgxYHJ",
        "outputId": "8768947e-10bb-49b0-d92f-d806d5d3f001"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_final =  model.predict(test)\n",
        "preds_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM_Zv43hxcDw",
        "outputId": "5957e114-01b3-46b0-df71-1648bba9f76a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_final_class = pd.DataFrame(np.argmax(preds_final, axis=1))\n",
        "preds_final = model.predict(test)\n",
        "preds_final_class = pd.DataFrame(np.argmax(preds_final, axis = 1))\n"
      ],
      "metadata": {
        "id": "52xFom7AxhGn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_final_class.to_csv('Submission.csv')\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "sample_submission['Label'] = preds_final_class\n",
        "sample_submission\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "x4LLDYEZxqHN",
        "outputId": "7bdd5b24-2da4-4d3e-8108-ab49563ff5a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ImageId  Label\n",
              "0            1      2\n",
              "1            2      0\n",
              "2            3      9\n",
              "3            4      8\n",
              "4            5      3\n",
              "...        ...    ...\n",
              "27995    27996      9\n",
              "27996    27997      7\n",
              "27997    27998      3\n",
              "27998    27999      9\n",
              "27999    28000      2\n",
              "\n",
              "[28000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba63a3cb-f2f4-42cf-acc8-0f45e2b8f2b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27995</th>\n",
              "      <td>27996</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>27997</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>27998</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>27999</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>28000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba63a3cb-f2f4-42cf-acc8-0f45e2b8f2b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba63a3cb-f2f4-42cf-acc8-0f45e2b8f2b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba63a3cb-f2f4-42cf-acc8-0f45e2b8f2b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.to_csv('Final_Submission.csv',index=False)\n",
        "sample_submission.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "36E7lvrVx4z6",
        "outputId": "a4630935-fa5c-4f31-fab6-3ef798579613"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ImageId         Label\n",
              "count  28000.000000  28000.000000\n",
              "mean   14000.500000      4.484857\n",
              "std     8083.048105      2.891984\n",
              "min        1.000000      0.000000\n",
              "25%     7000.750000      2.000000\n",
              "50%    14000.500000      4.000000\n",
              "75%    21000.250000      7.000000\n",
              "max    28000.000000      9.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4dca5702-6500-487a-b8f3-167847fb6e67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14000.500000</td>\n",
              "      <td>4.484857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8083.048105</td>\n",
              "      <td>2.891984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7000.750000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>14000.500000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>21000.250000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28000.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dca5702-6500-487a-b8f3-167847fb6e67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4dca5702-6500-487a-b8f3-167847fb6e67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4dca5702-6500-487a-b8f3-167847fb6e67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "waXf8uRPyJU-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}